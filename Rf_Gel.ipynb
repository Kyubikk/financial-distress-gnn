{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "qMxLDEMnGsEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0DfzgCtohHJ",
        "outputId": "c59e5cad-a051-4606-ac70-2818adc5d863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj35rvtEwunm",
        "outputId": "011db2f7-7b09-43ee-ad0f-a1de5d4658f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Using cached torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Using cached torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPARISION"
      ],
      "metadata": {
        "id": "4Qe1UMta_D84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=15,\n",
        "    min_samples_leaf=4,\n",
        "    min_samples_split=10,\n",
        "    max_features='sqrt',\n",
        "    bootstrap=True,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "hWGe6gsg_EUU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# BASELINE: 20 FEATURES\n",
        "# ===============================\n",
        "base_features = [f'X{i}' for i in range(1, 20)] + ['SEN']\n",
        "\n",
        "X_train = df_train[base_features].values\n",
        "y_train = y_train_raw\n",
        "X_test  = df_test[base_features].values\n",
        "y_test  = y_test\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "rf.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n===== BASELINE (20 FEATURES) =====\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsMksacW_HCx",
        "outputId": "69858df6-09c2-49c1-9c1a-92b5d4138831"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== BASELINE (20 FEATURES) =====\n",
            "[[707  43]\n",
            " [ 80 214]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8983    0.9427    0.9200       750\n",
            "           1     0.8327    0.7279    0.7768       294\n",
            "\n",
            "    accuracy                         0.8822      1044\n",
            "   macro avg     0.8655    0.8353    0.8484      1044\n",
            "weighted avg     0.8799    0.8822    0.8796      1044\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# FEATURE ENGINEERING: 44 FEATURES\n",
        "# ===============================\n",
        "fe_features = (\n",
        "    raw_features +\n",
        "    [f'{c}_rel' for c in raw_features] +\n",
        "    ['Altman_Z', 'Sector_Risk', 'SEN_delta', 'SEN_Altman']\n",
        ")\n",
        "\n",
        "X_train = df_train[fe_features].values\n",
        "X_test  = df_test[fe_features].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train_raw)\n",
        "\n",
        "rf.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n===== FEATURE ENGINEERING (44 FEATURES) =====\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ws6GRnK_IfE",
        "outputId": "e4bcffdc-f38b-4a9f-d45f-a030c05c3a60"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FEATURE ENGINEERING (44 FEATURES) =====\n",
            "[[715  35]\n",
            " [ 83 211]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8960    0.9533    0.9238       750\n",
            "           1     0.8577    0.7177    0.7815       294\n",
            "\n",
            "    accuracy                         0.8870      1044\n",
            "   macro avg     0.8769    0.8355    0.8526      1044\n",
            "weighted avg     0.8852    0.8870    0.8837      1044\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RF + Features Eng"
      ],
      "metadata": {
        "id": "332evXTdGREK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD DATA & MERGE SECTOR\n",
        "# ==========================================\n",
        "path_data = \"/content/drive/MyDrive/KLTN/FDP_VN_2010_2022_Train_Set.csv\"\n",
        "path_sector = \"/content/drive/MyDrive/KLTN/unique_company_with_sector (1).csv\"\n",
        "\n",
        "df = pd.read_csv(path_data)\n",
        "df_sector = pd.read_csv(path_sector)\n",
        "\n",
        "# Merge Sector\n",
        "df = df.merge(df_sector[['ticker', 'sector']], left_on='Code', right_on='ticker', how='left')\n",
        "df['sector'] = df['sector'].fillna('Unknown')\n",
        "\n",
        "# ==========================================\n",
        "# 2. FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "raw_features = [f'X{i}' for i in range(1, 20)] + ['SEN']\n",
        "\n",
        "def calculate_altman(row):\n",
        "    return 1.2*row['X2'] + 1.4*row['X8'] + 3.3*row['X4'] + 0.6*row['X18'] + 1.0*row['X9']\n",
        "df['Altman_Z'] = df.apply(calculate_altman, axis=1)\n",
        "\n",
        "for col in raw_features:\n",
        "    df[col] = df[col].fillna(0)\n",
        "    sector_medians = df.groupby(['Year', 'sector'])[col].transform('median')\n",
        "    df[f'{col}_rel'] = df[col] - sector_medians\n",
        "\n",
        "# C. Trend & SEN Interaction\n",
        "df = df.sort_values(['Code', 'Year'])\n",
        "df['SEN_delta'] = df.groupby('Code')['SEN'].diff().fillna(0)\n",
        "df['SEN_Altman'] = df['SEN'] * df['Altman_Z']\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# D. SECTOR RISK\n",
        "# ------------------------------------------------------------------------------\n",
        "df = df.sort_values(['sector', 'Year'])\n",
        "\n",
        "def calculate_expanding_risk(x):\n",
        "    return x.shift(1).expanding().mean()\n",
        "\n",
        "df['Sector_Risk'] = df.groupby('sector')['Next_year_binary_distress_label'].transform(calculate_expanding_risk)\n",
        "\n",
        "overall_train_mean = df.loc[df['Year'] <= 2021, 'Next_year_binary_distress_label'].mean()\n",
        "df['Sector_Risk'] = df['Sector_Risk'].fillna(overall_train_mean)\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "df = df.sort_values(['Code', 'Year'])\n",
        "\n",
        "# ==========================================\n",
        "# 3. SPLIT TRAIN (2010-2021) / TEST (2022)\n",
        "# ==========================================\n",
        "df_train = df[df['Year'] <= 2021].copy()\n",
        "df_test = df[df['Year'] == 2022].copy()\n",
        "\n",
        "x_cols = raw_features\n",
        "x_rel_cols = [f'{c}_rel' for c in raw_features]\n",
        "extra_cols = ['Altman_Z', 'Sector_Risk', 'SEN_delta', 'SEN_Altman']\n",
        "feature_cols = x_cols + x_rel_cols + extra_cols\n",
        "\n",
        "print(f\"    Tổng số Features: {len(feature_cols)}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_raw = scaler.fit_transform(df_train[feature_cols].values)\n",
        "y_train_raw = df_train['Next_year_binary_distress_label'].values.astype(int)\n",
        "\n",
        "X_test = scaler.transform(df_test[feature_cols].values)\n",
        "y_test = df_test['Next_year_binary_distress_label'].values.astype(int)\n",
        "\n",
        "# ==========================================\n",
        "# 4. SMOTE OVERSAMPLING\n",
        "# ==========================================\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train_raw, y_train_raw)\n",
        "\n",
        "print(f\"    Train shape gốc: {X_train_raw.shape}\")\n",
        "print(f\"    Train shape sau SMOTE: {X_train_res.shape}\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. HYPERPARAMETER TUNING\n",
        "# ==========================================\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [200, 300, 400],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [5, 10, 15],\n",
        "    'min_samples_leaf': [2, 4, 8],\n",
        "    'max_features': ['sqrt'],\n",
        "    'bootstrap': [True],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1, max_samples=0.9)\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "rf_search = RandomizedSearchCV(\n",
        "    estimator=rf_base,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    scoring='f1',\n",
        "    cv=tscv,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_search.fit(X_train_res, y_train_res)\n",
        "best_rf = rf_search.best_estimator_\n",
        "print(f\"\\n--> Best Parameters: {rf_search.best_params_}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. DỰ BÁO & TỐI ƯU THRESHOLD\n",
        "# ==========================================\n",
        "y_train_prob = best_rf.predict_proba(X_train_raw)[:, 1]\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(\n",
        "    y_train_raw, y_train_prob\n",
        ")\n",
        "\n",
        "f1_scores = 2 * precisions * recalls / (precisions + recalls + 1e-10)\n",
        "best_threshold = thresholds[np.argmax(f1_scores)]\n",
        "\n",
        "print(f\"\\nBest Threshold: {best_threshold:.4f}\")\n",
        "\n",
        "print(f\"\\n===== KẾT QUẢ TEST 2022 (Best Threshold: {best_threshold:.4f}) =====\")\n",
        "y_pred_opt = (y_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred_opt))\n",
        "print(classification_report(y_test, y_pred_opt, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F4PA7iW-fyb",
        "outputId": "7fc01350-5a5a-48b5-b279-e14060f02aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Tổng số Features: 44\n",
            "    Train shape gốc: (11634, 44)\n",
            "    Train shape sau SMOTE: (17554, 44)\n",
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "\n",
            "--> Best Parameters: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'class_weight': None, 'bootstrap': True}\n",
            "\n",
            "===== KẾT QUẢ TEST 2022 (Best Threshold: 0.5218) =====\n",
            "[[727  23]\n",
            " [ 83 211]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8975    0.9693    0.9321       750\n",
            "           1     0.9017    0.7177    0.7992       294\n",
            "\n",
            "    accuracy                         0.8985      1044\n",
            "   macro avg     0.8996    0.8435    0.8656      1044\n",
            "weighted avg     0.8987    0.8985    0.8947      1044\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_prob = best_rf.predict_proba(X_train_raw)[:, 1]\n",
        "y_train_pred = (y_train_prob >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\n===== TRAIN PERFORMANCE =====\")\n",
        "print(confusion_matrix(y_train_raw, y_train_pred))\n",
        "print(classification_report(y_train_raw, y_train_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdrN8Z55cy3u",
        "outputId": "f0079855-e717-4aa5-f394-273aa45b1862"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== TRAIN PERFORMANCE =====\n",
            "[[8644  133]\n",
            " [ 163 2694]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9815    0.9848    0.9832      8777\n",
            "           1     0.9530    0.9429    0.9479      2857\n",
            "\n",
            "    accuracy                         0.9746     11634\n",
            "   macro avg     0.9672    0.9639    0.9655     11634\n",
            "weighted avg     0.9745    0.9746    0.9745     11634\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances = best_rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "print(\"\\n=== TOP 20 BIẾN QUAN TRỌNG NHẤT ===\")\n",
        "for i in range(20):\n",
        "    print(f\"{i+1}. {feature_cols[indices[i]]}: {importances[indices[i]]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb4UZADCNFxq",
        "outputId": "f40bfc98-a895-4f59-c6a4-53d64a298f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TOP 20 BIẾN QUAN TRỌNG NHẤT ===\n",
            "1. X8: 0.1471\n",
            "2. X8_rel: 0.0904\n",
            "3. X4: 0.0639\n",
            "4. X7: 0.0593\n",
            "5. Altman_Z: 0.0490\n",
            "6. X4_rel: 0.0405\n",
            "7. SEN_Altman: 0.0348\n",
            "8. Sector_Risk: 0.0331\n",
            "9. X7_rel: 0.0304\n",
            "10. X6: 0.0234\n",
            "11. X3: 0.0192\n",
            "12. X6_rel: 0.0185\n",
            "13. X15: 0.0162\n",
            "14. X16: 0.0153\n",
            "15. SEN: 0.0150\n",
            "16. X2: 0.0149\n",
            "17. X9: 0.0148\n",
            "18. X17: 0.0145\n",
            "19. X15_rel: 0.0143\n",
            "20. X16_rel: 0.0134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_folder = \"/content/drive/MyDrive/KLTN/\"\n",
        "model_package = {\n",
        "    'model': best_rf,\n",
        "    'scaler': scaler,\n",
        "    'threshold': best_threshold,\n",
        "    'risk_map': risk_map,\n",
        "    'overall_mean': overall_mean,\n",
        "    'features': feature_cols\n",
        "}\n",
        "save_path = os.path.join(save_folder, 'fdp_rf_model_final.pkl')\n",
        "joblib.dump(model_package, save_path)\n",
        "print(f\"--> Lưu model tại: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18p4Mfa6NDmU",
        "outputId": "8b2b75d8-a1a0-4b70-dfdc-c1f87e10c701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Lưu model tại: /content/drive/MyDrive/KLTN/fdp_rf_model_final.pkl\n"
          ]
        }
      ]
    }
  ]
}