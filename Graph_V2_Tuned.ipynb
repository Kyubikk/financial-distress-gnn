{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gg0vm3CUu9Do",
    "outputId": "913de2fa-4889-423c-872c-058e1c22a91f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TabUELgYDLM"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OBWqqEyvJct",
    "outputId": "327d675b-23a0-42c7-bb4b-049d0c85d39c"
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "lcsVYc8NwyF-",
    "outputId": "a9d23f27-b13a-4694-b70d-f88db6d290b3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/KLTN/FDP_VN_1year_binary_FIN_WEIGHTED_SEN_2010_2022.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAHWMfbru9jf",
    "outputId": "47b1d131-423e-4df0-b0c3-e43df5ade1a9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Load graph mới\n",
    "data = torch.load(\n",
    "    \"/content/drive/MyDrive/KLTN/graph_data.pt\",\n",
    "    weights_only=False\n",
    ")\n",
    "data = data.to(device)\n",
    "\n",
    "print(data)\n",
    "print(\"Num nodes:\", data.num_nodes)\n",
    "print(\"Num edges:\", data.edge_index.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZFnSq_yvHNy"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8bkBMFMvf-6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjKq1DvgwY4s",
    "outputId": "d4653cff-b589-4b68-e382-eae9ec25998a"
   },
   "outputs": [],
   "source": [
    "# ===== TEMPORAL MASK (REBUILD FROM DF) =====\n",
    "years = df[\"Year\"].values\n",
    "\n",
    "train_mask = torch.tensor(years <= 2021, device=device)\n",
    "test_mask  = torch.tensor(years == 2022, device=device)\n",
    "\n",
    "print(\"Train samples:\", train_mask.sum().item())\n",
    "print(\"Test samples :\", test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wp654d95vh3Z",
    "outputId": "9b218462-9394-48c9-bc8c-3a084db5e544"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array([0,1]),\n",
    "    y=df.loc[years <= 2021, \"Next_year_binary_distress_label\"].values\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgLk_GVyIR4g"
   },
   "source": [
    "# Tuned RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN5N0l3QITcN",
    "outputId": "943dc134-f197-4cdb-91bc-8e3407796e59"
   },
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_n_ytIq8IeV7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v15UJb3qIf4a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/KLTN/FDP_VN_1year_binary_FIN_WEIGHTED_SEN_2010_2022.csv\"\n",
    ")\n",
    "\n",
    "df['Code'] = df['Code'].astype(str).str.strip().str.upper()\n",
    "df = df.sort_values(['Code', 'Year']).reset_index(drop=True)\n",
    "\n",
    "feature_cols = [f'X{i}' for i in range(1, 20)] + ['SEN']\n",
    "X = df[feature_cols].values\n",
    "y = df['Next_year_binary_distress_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKgCsIZlIhLC",
    "outputId": "9e8e7fe2-2d12-4475-e1b0-469a3becda33"
   },
   "outputs": [],
   "source": [
    "train_mask = df['Year'] <= 2021\n",
    "test_mask  = df['Year'] == 2022\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "print(\"Train:\", len(X_train))\n",
    "print(\"Test :\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqtq19qRIirh"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcZScXXIIkVA",
    "outputId": "7809d560-251b-45d7-90f3-6985fdcdec83"
   },
   "outputs": [],
   "source": [
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy='auto',\n",
    "    random_state=42,\n",
    "    k_neighbors=5\n",
    ")\n",
    "\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"After SMOTE :\", np.bincount(y_train_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6krASKsIlvv",
    "outputId": "ea59e7db-d251-4759-a86f-0ae4cba369c0"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "print(\"RF trained with SMOTE + scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPdChhLaInha",
    "outputId": "a2272f7a-39b8-4ae1-d0fc-81ef71e7db46"
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n===== FINAL TEST (2022) – RF + SMOTE + SCALING =====\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6S2mD1TgJsb1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2TELHGcJYbZ",
    "outputId": "6942cd91-a856-40d4-a863-72ac916a1349"
   },
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "data = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/KLTN/FDP_VN_1year_binary_FIN_WEIGHTED_SEN_2010_2022.csv\"\n",
    ")\n",
    "arr = data.to_numpy()\n",
    "\n",
    "# FEATURES / LABEL\n",
    "colxx = 21 + 1  # 19 FIN + SEN\n",
    "X = arr[:, 2:colxx].astype(float)\n",
    "Y = arr[:, colxx:colxx+1]\n",
    "\n",
    "# GLOBAL Z-SCORE (NHƯ CODE GỐC)\n",
    "X = stats.zscore(X, axis=0)\n",
    "\n",
    "# SPLIT BY INDEX\n",
    "rowxx = 11634\n",
    "X_train = X[:rowxx]\n",
    "X_test  = X[rowxx:]\n",
    "y_train = np.ravel(Y[:rowxx]).astype(int)\n",
    "y_test  = np.ravel(Y[rowxx:]).astype(int)\n",
    "\n",
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "\n",
    "# SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTE :\", np.bincount(y_train_sm))\n",
    "\n",
    "# RANDOM FOREST (Y NGUYÊN THAM SỐ)\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# TEST\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n===== RF + ZSCORE (GLOBAL) + SMOTE =====\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFti9fStKd1Y",
    "outputId": "8272f0e3-9c8e-4d7e-f5c8-78860a0dc3e1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/KLTN/FDP_VN_1year_binary_FIN_WEIGHTED_SEN_2010_2022.csv\"\n",
    ")\n",
    "arr = data.to_numpy()\n",
    "\n",
    "colxx = 21 + 1  # 19 FIN + SEN\n",
    "X = arr[:, 2:colxx].astype(float)\n",
    "Y = arr[:, colxx:colxx+1]\n",
    "\n",
    "mean = X_train.mean(axis=0)\n",
    "std  = X_train.std(axis=0)\n",
    "\n",
    "# tránh chia cho 0\n",
    "std[std == 0] = 1.0\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test  = (X_test  - mean) / std\n",
    "\n",
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTE :\", np.bincount(y_train_sm))\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n===== RF + ZSCORE (TRAIN ONLY) + SMOTE =====\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdTtSKgFKD58",
    "outputId": "366679cf-eae7-4788-e0e8-e4c318539354"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/KLTN/FDP_VN_1year_binary_FIN_WEIGHTED_SEN_2010_2022.csv\"\n",
    ")\n",
    "\n",
    "arr = data.to_numpy()\n",
    "\n",
    "# Split predictors and true label\n",
    "colxx = 21 + 1   # 19 FIN + SEN\n",
    "X = arr[:, 2:colxx].astype(float)\n",
    "Y = arr[:, colxx:colxx+1]\n",
    "\n",
    "X = stats.zscore(X, axis=0)\n",
    "\n",
    "rowxx = 11634\n",
    "X_train = X[:rowxx]\n",
    "X_test  = X[rowxx:]\n",
    "\n",
    "y_train = np.ravel(Y[:rowxx]).astype(int)\n",
    "y_test  = np.ravel(Y[rowxx:]).astype(int)\n",
    "\n",
    "print(\"Train distribution:\", np.bincount(y_train))\n",
    "print(\"Test distribution :\", np.bincount(y_test))\n",
    "\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"XGBoost trained.\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"\\n===== XGBOOST + GLOBAL ZSCORE (NO SMOTE) =====\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jHl-XPvzY6U"
   },
   "source": [
    "# SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_i99KjDvjlB"
   },
   "outputs": [],
   "source": [
    "def tune_graphsage(data, train_mask):\n",
    "    hidden_dims = [32, 64, 128]\n",
    "    lrs = [5e-4, 1e-3, 3e-3]\n",
    "    dropouts = [0.3, 0.5]\n",
    "    weight_decays = [1e-4, 5e-4]\n",
    "    use_weighted_loss = [False, True]\n",
    "\n",
    "    train_idx = train_mask.nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "    y_train = data.y[train_mask].cpu().numpy()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_cfg = None\n",
    "\n",
    "    for hd in hidden_dims:\n",
    "        for lr in lrs:\n",
    "            for dp in dropouts:\n",
    "                for wd in weight_decays:\n",
    "                    for weighted in use_weighted_loss:\n",
    "\n",
    "                        fold_f1 = []\n",
    "\n",
    "                        for tr, val in skf.split(train_idx, y_train):\n",
    "                            tr_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "                            val_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "\n",
    "                            tr_mask[train_idx[tr]] = True\n",
    "                            val_mask[train_idx[val]] = True\n",
    "\n",
    "                            model = GraphSAGE(\n",
    "                                in_dim=data.x.shape[1],\n",
    "                                hidden_dim=hd,\n",
    "                                out_dim=2,\n",
    "                                dropout=dp\n",
    "                            ).to(device)\n",
    "\n",
    "                            opt = torch.optim.Adam(\n",
    "                                model.parameters(),\n",
    "                                lr=lr,\n",
    "                                weight_decay=wd\n",
    "                            )\n",
    "\n",
    "                            for epoch in range(50):\n",
    "                                model.train()\n",
    "                                opt.zero_grad()\n",
    "                                out = model(data)\n",
    "\n",
    "                                if weighted:\n",
    "                                    loss = F.cross_entropy(\n",
    "                                        out[tr_mask],\n",
    "                                        data.y[tr_mask],\n",
    "                                        weight=class_weights\n",
    "                                    )\n",
    "                                else:\n",
    "                                    loss = F.cross_entropy(\n",
    "                                        out[tr_mask],\n",
    "                                        data.y[tr_mask]\n",
    "                                    )\n",
    "\n",
    "                                loss.backward()\n",
    "                                opt.step()\n",
    "\n",
    "                            model.eval()\n",
    "                            with torch.no_grad():\n",
    "                                preds = model(data)[val_mask].argmax(dim=1)\n",
    "                                f1 = f1_score(\n",
    "                                    data.y[val_mask].cpu(),\n",
    "                                    preds.cpu(),\n",
    "                                    average=\"macro\"\n",
    "                                )\n",
    "                                fold_f1.append(f1)\n",
    "\n",
    "                        mean_f1 = np.mean(fold_f1)\n",
    "\n",
    "                        if mean_f1 > best_f1:\n",
    "                            best_f1 = mean_f1\n",
    "                            best_cfg = (hd, lr, dp, wd, weighted)\n",
    "\n",
    "                        print(\n",
    "                            f\"hd={hd}, lr={lr}, dp={dp}, wd={wd}, weighted={weighted} → F1={mean_f1:.4f}\"\n",
    "                        )\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"BEST GraphSAGE (new graph)\")\n",
    "    print(\"Macro-F1:\", best_f1)\n",
    "    print(\"Config:\", best_cfg)\n",
    "    print(\"==============================\")\n",
    "\n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RiAo8ceNvk8M",
    "outputId": "304f6d56-9401-4a06-e7ce-ac2729b8b3a6"
   },
   "outputs": [],
   "source": [
    "best_cfg = tune_graphsage(data, train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPK-WFNRvnBP"
   },
   "outputs": [],
   "source": [
    "def final_test_graphsage(data, cfg, train_mask, test_mask):\n",
    "    hd, lr, dp, wd, weighted = cfg\n",
    "\n",
    "    model = GraphSAGE(\n",
    "        in_dim=data.x.shape[1],\n",
    "        hidden_dim=hd,\n",
    "        out_dim=2,\n",
    "        dropout=dp\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd\n",
    "    )\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        out = model(data)\n",
    "\n",
    "        if weighted:\n",
    "            loss = F.cross_entropy(\n",
    "                out[train_mask],\n",
    "                data.y[train_mask],\n",
    "                weight=class_weights\n",
    "            )\n",
    "        else:\n",
    "            loss = F.cross_entropy(\n",
    "                out[train_mask],\n",
    "                data.y[train_mask]\n",
    "            )\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        preds = logits[test_mask].argmax(dim=1).cpu().numpy()\n",
    "        labels = data.y[test_mask].cpu().numpy()\n",
    "\n",
    "    print(\"\\n===== FINAL TEST (2022) – GraphSAGE (new graph) =====\")\n",
    "    print(classification_report(labels, preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOBYXiEZvo47",
    "outputId": "3ad251e3-b439-4471-e91a-4b7b0263d5df"
   },
   "outputs": [],
   "source": [
    "final_test_graphsage(data, best_cfg, train_mask, test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyCiFdNzzVQO"
   },
   "source": [
    "# GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gocfKdjqvqVD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWYR2wtQzyqm"
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKYxl2P9zbou"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FktOYS8zdar"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "model = GAT(\n",
    "    in_dim=data.num_features,\n",
    "    hidden_dim=32,     # có thể thử 64\n",
    "    out_dim=2,\n",
    "    heads=4,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.005,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HuDMrtAz0Q9"
   },
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=32, out_dim=2, heads=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gat1 = GATConv(\n",
    "            in_dim,\n",
    "            hidden_dim,\n",
    "            heads=heads,\n",
    "            dropout=dropout,\n",
    "            add_self_loops=True\n",
    "        )\n",
    "\n",
    "        self.gat2 = GATConv(\n",
    "            hidden_dim * heads,\n",
    "            out_dim,\n",
    "            heads=1,\n",
    "            concat=False,\n",
    "            dropout=dropout,\n",
    "            add_self_loops=True\n",
    "        )\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V926ytmgz5Da"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "model = GAT(\n",
    "    in_dim=data.num_features,\n",
    "    hidden_dim=32,\n",
    "    out_dim=2,\n",
    "    heads=4,\n",
    "    dropout=0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcjLmE0L0Ljl"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.005,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtPEB4ci0M7R"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(\n",
    "        out[train_mask],\n",
    "        data.y[train_mask]\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMBdNFmv0OPV"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    y_true = data.y[test_mask].cpu().numpy()\n",
    "    y_pred = pred[test_mask].cpu().numpy()\n",
    "\n",
    "    print(\"\\n===== FINAL TEST (2022) – GAT (new graph) =====\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwDwdEkO0Pvk",
    "outputId": "cd15da1b-3c0a-4831-adf8-bb50de51c8a4"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = train()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f}\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPatyqjs1fQD"
   },
   "source": [
    "Although the proposed sparse and sector-aware graph structure is theoretically suitable for attention-based GNNs, empirical results show that GAT does not outperform GraphSAGE on this dataset. This suggests that when neighborhood nodes exhibit high feature similarity and label noise, attention mechanisms may fail to provide additional discriminative power and can even amplify noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4iAQz8L1_ME"
   },
   "source": [
    "# R-GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKnuALW56he7"
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ki--S3vd0QxE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvxwk8HQ2mFu"
   },
   "outputs": [],
   "source": [
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=32, out_dim=2, num_relations=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = RGCNConv(\n",
    "            in_dim,\n",
    "            hidden_dim,\n",
    "            num_relations=num_relations\n",
    "        )\n",
    "\n",
    "        self.conv2 = RGCNConv(\n",
    "            hidden_dim,\n",
    "            out_dim,\n",
    "            num_relations=num_relations\n",
    "        )\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8XXi07m2ny4"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.edge_index, data.edge_type)\n",
    "\n",
    "    loss = F.cross_entropy(\n",
    "        out[train_mask],\n",
    "        data.y[train_mask],\n",
    "        weight=class_weights    # nếu không muốn, xóa dòng này\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_NTz_Nz2qM9"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_type)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    y_true = data.y[test_mask].cpu().numpy()\n",
    "    y_pred = pred[test_mask].cpu().numpy()\n",
    "\n",
    "    print(\"\\n===== FINAL TEST (2022) – R-GCN (new graph) =====\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3iLeX9K4N5_"
   },
   "outputs": [],
   "source": [
    "model = RGCN(\n",
    "    in_dim=data.num_features,\n",
    "    hidden_dim=32,\n",
    "    out_dim=2,\n",
    "    num_relations=int(data.edge_type.max().item() + 1),\n",
    "    dropout=0.5\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZRhbyi14v2q"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.005,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dft0-OGp2rqI",
    "outputId": "a0603b64-a91c-4ac9-c9b1-5f0b902fc9d8"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = train()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f}\")\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
