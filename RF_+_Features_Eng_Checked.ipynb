{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "qMxLDEMnGsEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0DfzgCtohHJ",
        "outputId": "b38e2e8c-cca8-4f06-ab52-89c13c501fa8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RF + Features Eng"
      ],
      "metadata": {
        "id": "332evXTdGREK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD DATA & MERGE SECTOR\n",
        "# ==========================================\n",
        "path_data = \"/content/drive/MyDrive/KLTN/FDP_VN_2010_2022_Train_Set.csv\"\n",
        "path_sector = \"/content/drive/MyDrive/KLTN/unique_company_with_sector (1).csv\"\n",
        "\n",
        "df = pd.read_csv(path_data)\n",
        "df_sector = pd.read_csv(path_sector)\n",
        "\n",
        "# Merge Sector\n",
        "df = df.merge(df_sector[['ticker', 'sector']], left_on='Code', right_on='ticker', how='left')\n",
        "df['sector'] = df['sector'].fillna('Unknown')\n",
        "\n",
        "# ==========================================\n",
        "# 2. FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "raw_features = [f'X{i}' for i in range(1, 20)] + ['SEN']\n",
        "\n",
        "# A. Altman Z-score Proxy\n",
        "def calculate_altman(row):\n",
        "    return 1.2*row['X2'] + 1.4*row['X8'] + 3.3*row['X4'] + 0.6*row['X18'] + 1.0*row['X9']\n",
        "df['Altman_Z'] = df.apply(calculate_altman, axis=1)\n",
        "\n",
        "# B. Sector Relative Features\n",
        "for col in raw_features:\n",
        "    sector_medians = df.groupby(['Year', 'sector'])[col].transform('median')\n",
        "    df[f'{col}_rel'] = df[col] - sector_medians\n",
        "\n",
        "# C. Trend & SEN Interaction\n",
        "df = df.sort_values(['Code', 'Year'])\n",
        "df['SEN_delta'] = df.groupby('Code')['SEN'].diff().fillna(0)\n",
        "df['SEN_Altman'] = df['SEN'] * df['Altman_Z']\n",
        "\n",
        "# D. Sector Risk (Target Encoding)\n",
        "train_indices = df[df['Year'] <= 2021].index\n",
        "overall_mean = df.loc[train_indices, 'Next_year_binary_distress_label'].mean()\n",
        "sector_stats = df.loc[train_indices].groupby('sector')['Next_year_binary_distress_label'].agg(['count', 'mean'])\n",
        "smoothing = 10\n",
        "risk_map = (sector_stats['count'] * sector_stats['mean'] + smoothing * overall_mean) / (sector_stats['count'] + smoothing)\n",
        "\n",
        "df['Sector_Risk'] = df['sector'].map(risk_map)\n",
        "df['Sector_Risk'] = df['Sector_Risk'].fillna(overall_mean)\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "# ==========================================\n",
        "# 3. SPLIT TRAIN (2010-2021) / TEST (2022)\n",
        "# ==========================================\n",
        "df_train = df[df['Year'] <= 2021].copy()\n",
        "df_test = df[df['Year'] == 2022].copy()\n",
        "\n",
        "# List Feature (44 features)\n",
        "x_cols = raw_features\n",
        "x_rel_cols = [f'{c}_rel' for c in raw_features]\n",
        "extra_cols = ['Altman_Z', 'Sector_Risk', 'SEN_delta', 'SEN_Altman']\n",
        "feature_cols = x_cols + x_rel_cols + extra_cols\n",
        "\n",
        "print(f\"--> Tổng số Features: {len(feature_cols)}\")\n",
        "\n",
        "# Scale dữ liệu\n",
        "scaler = StandardScaler()\n",
        "X_train_raw = scaler.fit_transform(df_train[feature_cols].values)\n",
        "y_train_raw = df_train['Next_year_binary_distress_label'].values.astype(int)\n",
        "\n",
        "X_test = scaler.transform(df_test[feature_cols].values)\n",
        "y_test = df_test['Next_year_binary_distress_label'].values.astype(int)\n",
        "\n",
        "# ==========================================\n",
        "# 4. SMOTE OVERSAMPLING (Thay thế Manual)\n",
        "# ==========================================\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train_raw, y_train_raw)\n",
        "\n",
        "print(f\"    Train shape gốc: {X_train_raw.shape}\")\n",
        "print(f\"    Train shape sau SMOTE: {X_train_res.shape}\")\n",
        "print(f\"    Label distribution sau SMOTE: {np.bincount(y_train_res)}\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. HYPERPARAMETER TUNING (RandomizedSearchCV)\n",
        "# ==========================================\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [10, 15, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4, 6],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'bootstrap': [True, False],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "rf_search = RandomizedSearchCV(\n",
        "    estimator=rf_base,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    scoring='f1',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "best_rf = rf_search.best_estimator_\n",
        "print(f\"\\n--> Best Parameters: {rf_search.best_params_}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. DỰ BÁO & TỐI ƯU THRESHOLD\n",
        "# ==========================================\n",
        "y_prob = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Tìm Threshold tối ưu\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(f\"\\n===== KẾT QUẢ CUỐI CÙNG (Best Threshold: {best_threshold:.4f}) =====\")\n",
        "y_pred_opt = (y_prob >= best_threshold).astype(int)\n",
        "print(confusion_matrix(y_test, y_pred_opt))\n",
        "print(classification_report(y_test, y_pred_opt, digits=4))\n",
        "\n",
        "# ==========================================\n",
        "# 7. FEATURE IMPORTANCE\n",
        "# ==========================================\n",
        "importances = best_rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"\\n=== TOP 20 BIẾN QUAN TRỌNG NHẤT ===\")\n",
        "for i in range(20):\n",
        "    print(f\"{i+1}. {feature_cols[indices[i]]}: {importances[indices[i]]:.4f}\")"
      ],
      "metadata": {
        "id": "GNMh-lOIEtPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539f8ce0-97fe-4630-b92b-fd4573275e31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Tổng số Features: 44\n",
            "    Train shape gốc: (11634, 44)\n",
            "    Train shape sau SMOTE: (17554, 44)\n",
            "    Label distribution sau SMOTE: [8777 8777]\n",
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "\n",
            "--> Best Parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'class_weight': None, 'bootstrap': False}\n",
            "\n",
            "===== KẾT QUẢ CUỐI CÙNG (Best Threshold: 0.5024) =====\n",
            "[[728  22]\n",
            " [ 83 211]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8977    0.9707    0.9327       750\n",
            "           1     0.9056    0.7177    0.8008       294\n",
            "\n",
            "    accuracy                         0.8994      1044\n",
            "   macro avg     0.9016    0.8442    0.8667      1044\n",
            "weighted avg     0.8999    0.8994    0.8956      1044\n",
            "\n",
            "\n",
            "=== TOP 20 BIẾN QUAN TRỌNG NHẤT ===\n",
            "1. X8: 0.1592\n",
            "2. X8_rel: 0.0665\n",
            "3. X7: 0.0662\n",
            "4. X4: 0.0650\n",
            "5. Altman_Z: 0.0429\n",
            "6. X4_rel: 0.0357\n",
            "7. Sector_Risk: 0.0342\n",
            "8. SEN_Altman: 0.0335\n",
            "9. X7_rel: 0.0324\n",
            "10. X6: 0.0220\n",
            "11. X6_rel: 0.0197\n",
            "12. X15: 0.0174\n",
            "13. X3: 0.0171\n",
            "14. X16: 0.0159\n",
            "15. SEN: 0.0158\n",
            "16. X2: 0.0157\n",
            "17. X15_rel: 0.0150\n",
            "18. X17: 0.0149\n",
            "19. X9: 0.0147\n",
            "20. X16_rel: 0.0142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/KLTN/\"\n",
        "\n",
        "model_package = {\n",
        "    'model': best_rf,\n",
        "    'scaler': scaler,\n",
        "    'threshold': best_threshold,\n",
        "    'risk_map': risk_map,\n",
        "    'overall_mean': overall_mean,\n",
        "    'features': feature_cols\n",
        "}\n",
        "save_path = os.path.join(save_folder, 'fdp_rf_model_full.pkl')\n",
        "\n",
        "joblib.dump(model_package, save_path)\n",
        "\n",
        "print(f\"Lưu file tại: {save_path}\")\n",
        "print(\"File bao gồm: Model, Scaler, Threshold, Risk Map và Feature List.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTU4bkJcDaF3",
        "outputId": "1b4bef84-3872-4853-f984-b6e45af4e302"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lưu file tại: /content/drive/MyDrive/KLTN/fdp_rf_model_full.pkl\n",
            "File bao gồm: Model, Scaler, Threshold, Risk Map và Feature List.\n"
          ]
        }
      ]
    }
  ]
}